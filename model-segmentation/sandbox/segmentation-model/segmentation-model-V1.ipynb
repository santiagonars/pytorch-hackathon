{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597008847236",
   "display_name": "Python 3.7.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation Model (Version 1)\n",
    "\n",
    "\n",
    "Steps:\n",
    "* Import Libraries + other dependencies\n",
    "* Load Image from URL\n",
    "* Load pre-trained model\n",
    "* Run inference on images\n",
    "* Extract inferences labels (From panoptic inferences)\n",
    "* Save inference masks (From instance inferences)\n",
    "\n",
    "Citation:\n",
    "@misc{wu2019detectron2,\n",
    "  author =       {Yuxin Wu and Alexander Kirillov and Francisco Massa and\n",
    "                  Wan-Yen Lo and Ross Girshick},\n",
    "  title =        {Detectron2},\n",
    "  howpublished = {\\url{https://github.com/facebookresearch/detectron2}},\n",
    "  year =         {2019}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Torch and Torchvisions\n",
    "# -> Make sure to use correct version for instance used\n",
    "\n",
    "# Install detectron2\n",
    "# -> Make sure to use correct version for instance\n",
    "# -> See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
    "\n",
    "# pip install pyyaml==5.1    #or => pip3 install pyyaml==5.1\n",
    "# pip install pycocotools    #or => pip3 install pycocotools\n",
    "# pip install opencv-python  #or => pip3 install opencv-python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries and Load Dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Torch Version: 1.5.1\nCUDA available: False\n"
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "print(\"Torch Version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "# import common libraries\n",
    "import os, json, random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import requests\n",
    "from requests.exceptions import HTTPError, Timeout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load test Images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def httpGetRequest(url):\n",
    "    # Use requests to issue a standard HTTP GET \n",
    "    try:\n",
    "        result = requests.get(url ,timeout=15)\n",
    "        # raise_for_status will throw an exception if an HTTP error\n",
    "        result.raise_for_status\n",
    "        print(result)\n",
    "        return result\n",
    "    except HTTPError as err:\n",
    "        print(\"Error: {0}\".format(err))\n",
    "    except Timeout as err:\n",
    "        print(\"Request time out {0}\".format(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<Response [200]>\n"
    }
   ],
   "source": [
    "# load image\n",
    "image_response = httpGetRequest(\"https://storage.googleapis.com/segmentation-testing/testing_images1/bikes.jpeg\")\n",
    "# get image as numpy array\n",
    "image_NumpyArray = np.frombuffer(image_response.content, np.uint8)\n",
    "image = cv2.imdecode(image_NumpyArray, cv2.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD PRE-TRAINED MODEL:\n",
    "\n",
    "Then, we create a detectron2 config and a detectron2 `DefaultPredictor` to run inference on this image.\n",
    "\n",
    "* Use cfg.MODEL.DEVICE='cpu' only if you don't have a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------- build model: ----------\n",
    "cfg = get_cfg()\n",
    "# add config \n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml\"))\n",
    "# set threshold for this model; means that inference has to be greater than 50%\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  \n",
    "# Find a model weights\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml\")\n",
    "# ***Add line below only if inference will be made on a CPU:\n",
    "cfg.MODEL.DEVICE='cpu'\n",
    "#run inference against predictor:\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions / inferences to images:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes about 10-15 seconds on CPU\n",
    "outputs = predictor(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": ">>> Instance segmentation classes prediction:\n tensor([ 0,  0,  1,  1, 39])\n>>> Instance segmentation mask prediction:\n tensor([[[False, False, False,  ..., False, False, False],\n         [False, False, False,  ..., False, False, False],\n         [False, False, False,  ..., False, False, False],\n         ...,\n         [False, False, False,  ..., False, False, False],\n         [False, False, False,  ..., False, False, False],\n         [False, False, False,  ..., False, False, False]],\n\n        [[False, False, False,  ..., False, False, False],\n         [False, False, False,  ..., False, False, False],\n         [False, False, False,  ..., False, False, False],\n         ...,\n         [False, False, False,  ..., False, False, False],\n         [False, False, False,  ..., False, False, False],\n         [False, False, False,  ..., False, False, False]],\n\n        [[False, False, False,  ..., False, False, False],\n         [False, False, False,  ..., False, False, False],\n         [False, False, False,  ..., False, False, False],\n         ...,\n         [False, False, False,  ..., False, False, False],\n         [False, False, False,  ..., False, False, False],\n         [False, False, False,  ..., False, False, False]],\n\n        [[False, False, False,  ..., False, False, False],\n         [False, False, False,  ..., False, False, False],\n         [False, False, False,  ..., False, False, False],\n         ...,\n         [False, False, False,  ..., False, False, False],\n         [False, False, False,  ..., False, False, False],\n         [False, False, False,  ..., False, False, False]],\n\n        [[False, False, False,  ..., False, False, False],\n         [False, False, False,  ..., False, False, False],\n         [False, False, False,  ..., False, False, False],\n         ...,\n         [False, False, False,  ..., False, False, False],\n         [False, False, False,  ..., False, False, False],\n         [False, False, False,  ..., False, False, False]]])\n>>> Panoptic segmentation mask prediction:\n [{'id': 1, 'isthing': True, 'score': 0.999495267868042, 'category_id': 0, 'instance_id': 0}, {'id': 2, 'isthing': True, 'score': 0.9988834261894226, 'category_id': 0, 'instance_id': 1}, {'id': 3, 'isthing': True, 'score': 0.9974486231803894, 'category_id': 1, 'instance_id': 2}, {'id': 4, 'isthing': True, 'score': 0.9939423203468323, 'category_id': 1, 'instance_id': 3}, {'id': 5, 'isthing': False, 'category_id': 21, 'area': 122946}, {'id': 6, 'isthing': False, 'category_id': 23, 'area': 81396}, {'id': 7, 'isthing': False, 'category_id': 24, 'area': 34879}, {'id': 8, 'isthing': False, 'category_id': 37, 'area': 6769}, {'id': 9, 'isthing': False, 'category_id': 40, 'area': 281030}]\n"
    }
   ],
   "source": [
    "# output values needed to return \n",
    "print(\">>> Instance segmentation classes prediction:\\n\", outputs[\"instances\"].pred_classes)\n",
    "print(\">>> Instance segmentation mask prediction:\\n\", outputs[\"instances\"].pred_masks)\n",
    "print(\">>> Panoptic segmentation mask prediction:\\n\", outputs[\"panoptic_seg\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract labels (Panoptic Segmentation Inference):\n",
    "\n",
    "* Get the image labels from the panoptic segmentation prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load classes\n",
    "thing_classes=['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "stuff_classes=['things', 'banner', 'blanket', 'bridge', 'cardboard', 'counter', 'curtain', 'door-stuff', 'floor-wood', 'flower', 'fruit', 'gravel', 'house', 'light', 'mirror-stuff', 'net', 'pillow', 'platform', 'playingfield', 'railroad', 'river', 'road', 'roof', 'sand', 'sea', 'shelf', 'snow', 'stairs', 'tent', 'towel', 'wall-brick', 'wall-stone', 'wall-tile', 'wall-wood', 'water', 'window-blind', 'window', 'tree', 'fence', 'ceiling', 'sky', 'cabinet', 'table', 'floor', 'pavement', 'mountain', 'grass', 'dirt', 'paper', 'food', 'building', 'rock', 'wall', 'rug']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'id': 1, 'isthing': True, 'score': 0.999495267868042, 'category_id': 0, 'instance_id': 0}\n{'id': 2, 'isthing': True, 'score': 0.9988834261894226, 'category_id': 0, 'instance_id': 1}\n{'id': 3, 'isthing': True, 'score': 0.9974486231803894, 'category_id': 1, 'instance_id': 2}\n{'id': 4, 'isthing': True, 'score': 0.9939423203468323, 'category_id': 1, 'instance_id': 3}\n{'id': 5, 'isthing': False, 'category_id': 21, 'area': 122946}\n{'id': 6, 'isthing': False, 'category_id': 23, 'area': 81396}\n{'id': 7, 'isthing': False, 'category_id': 24, 'area': 34879}\n{'id': 8, 'isthing': False, 'category_id': 37, 'area': 6769}\n{'id': 9, 'isthing': False, 'category_id': 40, 'area': 281030}\n\n[[0, True], [0, True], [1, True], [1, True], [21, False], [23, False], [24, False], [37, False], [40, False]]\n\n"
    }
   ],
   "source": [
    "#Get class ID (category_id) and the class it belongs to (bool)\n",
    "classID = list()\n",
    "for i in range(len(outputs[\"panoptic_seg\"][1])):\n",
    "\n",
    "    classID.append([outputs[\"panoptic_seg\"][1][i]['category_id'], outputs[\"panoptic_seg\"][1][i]['isthing']])\n",
    "    print(outputs[\"panoptic_seg\"][1][i])\n",
    "\n",
    "print(\"\")\n",
    "print(classID)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": ">>>things class: ['person', 'person', 'bicycle', 'bicycle']\n>>>stuff class: ['road', 'sand', 'sea', 'tree', 'sky']\n"
    }
   ],
   "source": [
    "# display labels extracted\n",
    "# TODO: Labels might need to be a dictionary to be the corresponding value of an imageID key\n",
    "labels_things= list()\n",
    "labels_stuff = list()\n",
    "for i in range(len(classID)):\n",
    "    if classID[i][1] == True:\n",
    "        # print(thing_classes[classID[i][0]])\n",
    "        labels_things.append(thing_classes[classID[i][0]])\n",
    "    else:\n",
    "        # print(stuff_classes[classID[i][0]])\n",
    "        labels_stuff.append(stuff_classes[classID[i][0]])\n",
    "\n",
    "print(\">>>things class:\", labels_things)\n",
    "print(\">>>stuff class:\", labels_stuff) # <--- we might only need the this result as input for the GAN models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Masks (Instance segmentation):\n",
    "\n",
    "* Get the masks from the Instance segmentation prediction\n",
    "* We are using these masks because overlap which is what we need as inputs the GAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert Torch Tensors to a NumPy Arrays\n",
    "# print(outputs[\"instances\"].pred_classes.numpy())\n",
    "# print(outputs[\"instances\"].pred_masks.numpy())\n",
    "\n",
    "# store numpy arrays in for mask class and mask\n",
    "maskClass = outputs[\"instances\"].pred_classes.numpy()\n",
    "masksInferences =outputs[\"instances\"].pred_masks.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0, 0, 1, 1, 39]\n"
    }
   ],
   "source": [
    "#Get class ID (category_id) and the class it belongs to (bool)\n",
    "maskClassID = list()\n",
    "for i in range(len(maskClass)):\n",
    "    # print(maskClass[i])\n",
    "    maskClassID.append(maskClass[i])\n",
    "    \n",
    "print(maskClassID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['person', 'person', 'bicycle', 'bicycle', 'bottle']\n"
    }
   ],
   "source": [
    "# display labels extracted\n",
    "masksInferences\n",
    "# TODO: might need to store as dictionaries and then convert to json maybe (depends on database)\n",
    "maskInference_labels = list()\n",
    "for i in range(len(maskClassID)):\n",
    "    # print(thing_classes[maskClassID[i]])\n",
    "    maskInference_labels.append(thing_classes[maskClassID[i]])\n",
    "\n",
    "print(maskInference_labels) #notice how instance seg classified one/more things than the panoptic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "---------------------------\nLabel: person\n[[False False False ... False False False]\n [False False False ... False False False]\n [False False False ... False False False]\n ...\n [False False False ... False False False]\n [False False False ... False False False]\n [False False False ... False False False]]\n---------------------------\nLabel: person\n[[False False False ... False False False]\n [False False False ... False False False]\n [False False False ... False False False]\n ...\n [False False False ... False False False]\n [False False False ... False False False]\n [False False False ... False False False]]\n---------------------------\nLabel: bicycle\n[[False False False ... False False False]\n [False False False ... False False False]\n [False False False ... False False False]\n ...\n [False False False ... False False False]\n [False False False ... False False False]\n [False False False ... False False False]]\n---------------------------\nLabel: bicycle\n[[False False False ... False False False]\n [False False False ... False False False]\n [False False False ... False False False]\n ...\n [False False False ... False False False]\n [False False False ... False False False]\n [False False False ... False False False]]\n---------------------------\nLabel: bottle\n[[False False False ... False False False]\n [False False False ... False False False]\n [False False False ... False False False]\n ...\n [False False False ... False False False]\n [False False False ... False False False]\n [False False False ... False False False]]\n"
    }
   ],
   "source": [
    "# TODO: Find out we will store the mask which is a multidimensial numpy array (Database???)\n",
    "# print(len(masksInferences))\n",
    "for i in range(0, len(masksInferences)):\n",
    "    print(\"---------------------------\")\n",
    "    print(\"Label:\", maskInference_labels[i])\n",
    "    print(masksInferences[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}